{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "iwADyeVCYr5l"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import os\n",
        "import tarfile\n",
        "import urllib\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Q2k4zrFYzVJ"
      },
      "outputs": [],
      "source": [
        "def load_data(filename):\n",
        "\n",
        "    with open(filename, 'rb') as f:\n",
        "        datadict = pickle.load(f, encoding='bytes')\n",
        "        X = datadict[b'data']\n",
        "        X = X.reshape(10000,3072)\n",
        "        y = datadict[b'labels']\n",
        "        y = np.array(y)\n",
        "        return X, y\n",
        "\n",
        "def get_data(arr):\n",
        "    X = []\n",
        "    y = []\n",
        "    for i in arr:\n",
        "        a,b=load_data(i)\n",
        "        X.append(a)\n",
        "        y.append(b)\n",
        "        del a,b\n",
        "    X = np.concatenate(X)\n",
        "    y = np.concatenate(y)\n",
        "\n",
        "    X = X/255\n",
        "    return X, y\n",
        "\n",
        "def load_data_test(filename):\n",
        "    \n",
        "    with open(filename, 'rb') as f:\n",
        "        datadict = pickle.load(f, encoding='bytes')\n",
        "        X_test = np.asarray(datadict[b'data'])\n",
        "        X_test = X_test.reshape(10000,3072)\n",
        "        y_test = np.asarray(datadict[b'labels'])\n",
        "        return X_test/255, y_test\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "URL = 'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
        "FILE = 'cifar-10-python.tar.gz'\n",
        "\n",
        "if not os.path.isfile(FILE):\n",
        "  urllib.request.urlretrieve(URL, FILE)\n",
        "\n",
        "file = tarfile.open(FILE)\n",
        "print(file.getnames())\n",
        "file.extractall('./')\n",
        "file.close\n",
        "\n",
        "path = [\"./cifar-10-batches-py/data_batch_1\",\"./cifar-10-batches-py/data_batch_2\",\"./cifar-10-batches-py/data_batch_3\",\"./cifar-10-batches-py/data_batch_4\",\"./cifar-10-batches-py/data_batch_5\"]\n",
        "X, y = get_data(path)\n",
        "\n",
        "X_test, y_test = load_data_test(\"./cifar-10-batches-py/test_batch\")\n",
        "\n",
        "X = X.T\n",
        "\n",
        "X_test = X_test.T"
      ],
      "metadata": {
        "id": "1fJsq-mebnC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLVqv-9sZ6IH"
      },
      "outputs": [],
      "source": [
        "def relu(v):\n",
        "    return np.maximum(v, 0)\n",
        "\n",
        "def softmax(v):\n",
        "    activation = np.exp(v) / sum(np.exp(v))\n",
        "    return activation\n",
        "\n",
        "def derrelu(v):\n",
        "    return v > 0\n",
        "\n",
        "def ohe(y):\n",
        "    ym = np.zeros((y.size, y.max() + 1))\n",
        "    ym[np.arange(y.size), y] = 1\n",
        "    ym = ym.T\n",
        "    return ym"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def params():\n",
        "    weights1 = np.random.rand(100, 3072)-0.5\n",
        "    biases1 = np.random.rand(100, 1)-0.5\n",
        "    weights2 = np.random.rand(10, 100)-0.5\n",
        "    biases2 = np.random.rand(10, 1)-0.5\n",
        "    return weights1, biases1, weights2, biases2\n",
        "\n",
        "def predictions(activation):\n",
        "    return np.argmax(activation, 0)\n",
        "\n",
        "def accuracy(predictions, y):\n",
        "    return np.sum(predictions == y) / y.size"
      ],
      "metadata": {
        "id": "dhhYD44JAIZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQjJy1J7Z9fu"
      },
      "outputs": [],
      "source": [
        "def forward_propogation(weights1, biases1, weights2, biases2, X):\n",
        "    v1 = weights1.dot(X) + biases1\n",
        "    activation1 = relu(v1)\n",
        "    v2 = weights2.dot(activation1) + biases2\n",
        "    activation2 = softmax(v2)\n",
        "    return v1, activation1, v2, activation2\n",
        "\n",
        "def backward_propogation(v1, activation1, v2, activation2, weights1, biases1, weights2, biases2, X, y, alpha, s):\n",
        "    ym = ohe(y)\n",
        "    derv2 = activation2 - ym\n",
        "    derweights2 = (1 / s) * derv2.dot(activation1.T)\n",
        "    derbiases2 = (1 / s) * np.sum(derv2)\n",
        "    derv1 = weights2.T.dot(derv2) * derrelu(v1)\n",
        "    derweights1 = (1 / s) * derv1.dot(X.T)\n",
        "    derbiases1 = (1 / s) * np.sum(derv1)\n",
        "    weights1 = weights1 - alpha * derweights1\n",
        "    biases1 = biases1 - alpha * derbiases1    \n",
        "    weights2 = weights2 - alpha * derweights2  \n",
        "    biases2 = biases2 - alpha * derbiases2    \n",
        "    return weights1, biases1, weights2, biases2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqopD3t-aGJ8"
      },
      "outputs": [],
      "source": [
        "def gradient_descent(X, y, alpha, s, epochs):\n",
        "    weights1, biases1, weights2, biases2 = params()\n",
        "    for i in range(epochs):\n",
        "      v1, activation1, v2, activation2 = forward_propogation(weights1, biases1, weights2, biases2, X)\n",
        "      weights1, biases1, weights2, biases2 = backward_propogation(v1, activation1, v2, activation2, weights1, biases1, weights2, biases2, X, y, alpha, s)\n",
        "      if i % 10 == 0:\n",
        "        preds = predictions(activation2)\n",
        "        print(\"Epoch: %d  Acuraccy: %f\" % (i, accuracy(preds, y)))\n",
        "    return weights1, biases1, weights2, biases2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIz4Y9noaI87"
      },
      "outputs": [],
      "source": [
        "weights1, biases1, weights2, biases2 = gradient_descent(X, y, 0.1, 50000, 25000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h33u0yLnaL-J"
      },
      "outputs": [],
      "source": [
        "def make_predictions(X, weights1, biases1, weights2, biases2):\n",
        "    _, _, _, activation2 = forward_propogation(weights1, biases1, weights2, biases2, X)\n",
        "    preds = predictions(activation2)\n",
        "    return preds\n",
        "\n",
        "\n",
        "make_predictions = make_predictions(X_test, weights1, biases1, weights2, biases2)\n",
        "print(accuracy(make_predictions, y_test))\n",
        "\n",
        "confusion_mtx = tf.math.confusion_matrix(make_predictions, y_test) \n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(confusion_mtx, annot=True, fmt = 'g')\n",
        "plt.xlabel('Prediction')\n",
        "plt.ylabel('Label')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "FCNN_IMP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}